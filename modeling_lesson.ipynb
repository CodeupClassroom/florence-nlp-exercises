{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increasing-inspection",
   "metadata": {},
   "source": [
    "# NLP Modeling\n",
    "\n",
    "How do we quantify a document?\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Data Representation](#data-representation)\n",
    "    - [Bag of Words](#bag-of-words)\n",
    "    - [TF-IDF](#tf-idf)\n",
    "    - [Bag Of Ngrams](#bag-of-ngrams)\n",
    "- [Modeling](#modeling)\n",
    "    - [Modeling Results](#modeling-results)\n",
    "- [Next Steps](#next-steps)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def clean(text: str) -> list:\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    text = (text.encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split() # tokenization\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-volume",
   "metadata": {},
   "source": [
    "## Data Representation\n",
    "\n",
    "Simple data for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    'Python is pretty cool',\n",
    "    'Python is a nice programming language with nice syntax',\n",
    "    'I think SQL is cool too',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-barbados",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bag_of_words = cv.fit_transform(data)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-bryan",
   "metadata": {},
   "source": [
    "Here `bag_of_words` is a **sparse matrix**. Usually you should keep it as such,\n",
    "but for demonstration we'll view the data within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(data)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-mystery",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "- a measure that helps identify how important a word is in a document\n",
    "- combination of how often a word appears in a document (**tf**) and how unqiue the word\n",
    "  is among documents (**idf**)\n",
    "- used by search engines\n",
    "- naturally helps filter out stopwords\n",
    "- tf is for a single document, idf is for a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidfs = tfidf.fit_transform(data)\n",
    "\n",
    "pprint(data)\n",
    "pd.DataFrame(tfidfs.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-appreciation",
   "metadata": {},
   "source": [
    "To get the idf score for each word (these aren't terribly usefule themselves):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-argument",
   "metadata": {},
   "source": [
    "### Bag Of Ngrams\n",
    "\n",
    "For either `CountVectorizer` or `TfidfVectorizer`, you can set the `ngram_range`\n",
    "parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2))\n",
    "bag_of_words = cv.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(data)\n",
    "pd.DataFrame(bag_of_words.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-parish",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "df = pd.read_csv('spam_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df.text.apply(clean).apply(' '.join))\n",
    "y = df.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=12)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "tree.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-poultry",
   "metadata": {},
   "source": [
    "### Modeling Results\n",
    "\n",
    "A super-useful feature of decision trees and linear models is that they do some\n",
    "built-in feature selection through the coefficeints or feature importances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dict(zip(cv.get_feature_names(), tree.feature_importances_))).sort_values().tail(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-pulse",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try other model types\n",
    "\n",
    "    [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "    ([`sklearn`\n",
    "    docs](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html))\n",
    "    is a very popular classifier for NLP tasks.\n",
    "\n",
    "- Look at other metrics, is accuracy the best choice here?\n",
    "\n",
    "- Try ngrams instead of single words\n",
    "\n",
    "- Try a combination of ngrams and words (`ngram_range=(1, 2)` for words and\n",
    "  bigrams)\n",
    "\n",
    "- Try using tf-idf instead of bag of words\n",
    "\n",
    "- Combine the top `n` performing words with the other features that you have\n",
    "  engineered (the `CountVectorizer` and `TfidfVectorizer` have a `vocabulary`\n",
    "  argument you can use to restrict the words used)\n",
    "\n",
    "    ```python\n",
    "    best_words = (\n",
    "        # or, e.g. lm.coef_\n",
    "        pd.Series(dict(zip(cv.get_feature_names(), tree.feature_importances_)))\n",
    "        .sort_values()\n",
    "        .tail(5)\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    cv = CountVectorizer(vocabulary=best_words)\n",
    "    X = cv.fit_transform(df.text.apply(clean).apply(' '.join))\n",
    "\n",
    "    # for demonstration\n",
    "    pd.DataFrame(X.todense(), columns=cv.get_feature_names())\n",
    "    ```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
